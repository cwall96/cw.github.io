
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Parallelization &#8212; Programming for Quantitative Economics</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/qe-logo-large.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Pandas" href="pandas.html" />
    <link rel="prev" title="Numba" href="numba.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/qe-logo-large.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Programming for Quantitative Economics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to Python
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="about_py.html">
   About Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="getting_started.html">
   Setting up Your Python Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="python_by_example.html">
   An Introductory Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="functions.html">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="python_essentials.html">
   Python Essentials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="oop_intro.html">
   OOP I: Introduction to Object Oriented Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="python_oop.html">
   OOP II: Building Classes
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Scientific Libraries
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="need_for_speed.html">
   Python for Scientific Computing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="numpy.html">
   NumPy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="matplotlib.html">
   Matplotlib
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="scipy.html">
   SciPy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="numba.html">
   Numba
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Parallelization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pandas.html">
   Pandas
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Advanced Python
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="writing_good_code.html">
   Writing Good Code
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="python_advanced_features.html">
   More Language Features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="debugging.html">
   Debugging
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/quantecon-example/master?urlpath=tree/book/docs/parallelization.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/quantecon-example/"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/quantecon-example/edit/master/book/docs/parallelization.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/docs/parallelization.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="../_sources/docs/parallelization.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#overview">
   Overview
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types-of-parallelization">
   Types of Parallelization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multiprocessing">
     Multiprocessing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multithreading">
     Multithreading
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#advantages-and-disadvantages">
     Advantages and Disadvantages
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#implicit-multithreading-in-numpy">
   Implicit Multithreading in NumPy
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-matrix-operation">
     A Matrix Operation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-multithreaded-ufunc">
     A Multithreaded Ufunc
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-comparison-with-numba">
     A Comparison with Numba
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multithreading-a-numba-ufunc">
     Multithreading a Numba Ufunc
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multithreaded-loops-in-numba">
   Multithreaded Loops in Numba
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-warning">
     A Warning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-1">
     Exercise 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#solutions">
   Solutions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Exercise 1
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Parallelization</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#overview">
   Overview
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types-of-parallelization">
   Types of Parallelization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multiprocessing">
     Multiprocessing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multithreading">
     Multithreading
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#advantages-and-disadvantages">
     Advantages and Disadvantages
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#implicit-multithreading-in-numpy">
   Implicit Multithreading in NumPy
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-matrix-operation">
     A Matrix Operation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-multithreaded-ufunc">
     A Multithreaded Ufunc
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-comparison-with-numba">
     A Comparison with Numba
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multithreading-a-numba-ufunc">
     Multithreading a Numba Ufunc
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multithreaded-loops-in-numba">
   Multithreaded Loops in Numba
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-warning">
     A Warning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-1">
     Exercise 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#solutions">
   Solutions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Exercise 1
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="parallelization">
<span id="parallel"></span><h1>Parallelization<a class="headerlink" href="#parallelization" title="Permalink to this headline">#</a></h1>
<p>In addition to what’s in Anaconda, this lecture will need the following
libraries:</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install --upgrade quantecon
</pre></div>
</div>
</div>
</div>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">#</a></h2>
<p>The growth of CPU clock speed (i.e., the speed at which a single chain
of logic can be run) has slowed dramatically in recent years.</p>
<p>This is unlikely to change in the near future, due to inherent physical
limitations on the construction of chips and circuit boards.</p>
<p>Chip designers and computer programmers have responded to the slowdown
by seeking a different path to fast execution: parallelization.</p>
<p>Hardware makers have increased the number of cores (physical CPUs)
embedded in each machine.</p>
<p>For programmers, the challenge has been to exploit these multiple CPUs
by running many processes in parallel (i.e., simultaneously).</p>
<p>This is particularly important in scientific programming, which requires
handling</p>
<ul class="simple">
<li><p>large amounts of data and</p></li>
<li><p>CPU intensive simulations and other calculations.</p></li>
</ul>
<p>In this lecture we discuss parallelization for scientific computing,
with a focus on</p>
<ol class="simple">
<li><p>the best tools for parallelization in Python and</p></li>
<li><p>how these tools can be applied to quantitative economic problems.</p></li>
</ol>
<p>Let’s start with some imports:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">quantecon</span> <span class="k">as</span> <span class="nn">qe</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="types-of-parallelization">
<h2>Types of Parallelization<a class="headerlink" href="#types-of-parallelization" title="Permalink to this headline">#</a></h2>
<p>Large textbooks have been written on different approaches to
parallelization but we will keep a tight focus on what’s most useful to
us.</p>
<p>We will briefly review the two main kinds of parallelization commonly
used in scientific computing and discuss their pros and cons.</p>
<section id="multiprocessing">
<h3>Multiprocessing<a class="headerlink" href="#multiprocessing" title="Permalink to this headline">#</a></h3>
<p>Multiprocessing means concurrent execution of multiple processes using
more than one processor.</p>
<p>In this context, a <strong>process</strong> is a chain of instructions (i.e., a
program).</p>
<p>Multiprocessing can be carried out on one machine with multiple CPUs or
on a collection of machines connected by a network.</p>
<p>In the latter case, the collection of machines is usually called a
<strong>cluster</strong>.</p>
<p>With multiprocessing, each process has its own memory space, although
the physical memory chip might be shared.</p>
</section>
<section id="multithreading">
<h3>Multithreading<a class="headerlink" href="#multithreading" title="Permalink to this headline">#</a></h3>
<p>Multithreading is similar to multiprocessing, except that, during
execution, the threads all share the same memory space.</p>
<p>Native Python struggles to implement multithreading due to some <a class="reference external" href="https://wiki.python.org/moin/GlobalInterpreterLock">legacy
design features</a>.</p>
<p>But this is not a restriction for scientific libraries like NumPy and
Numba.</p>
<p>Functions imported from these libraries and JIT-compiled code run in low
level execution environments where Python’s legacy restrictions don’t
apply.</p>
</section>
<section id="advantages-and-disadvantages">
<h3>Advantages and Disadvantages<a class="headerlink" href="#advantages-and-disadvantages" title="Permalink to this headline">#</a></h3>
<p>Multithreading is more lightweight because most system and memory
resources are shared by the threads.</p>
<p>In addition, the fact that multiple threads all access a shared pool of
memory is extremely convenient for numerical programming.</p>
<p>On the other hand, multiprocessing is more flexible and can be
distributed across clusters.</p>
<p>For the great majority of what we do in these lectures, multithreading
will suffice.</p>
</section>
</section>
<section id="implicit-multithreading-in-numpy">
<h2>Implicit Multithreading in NumPy<a class="headerlink" href="#implicit-multithreading-in-numpy" title="Permalink to this headline">#</a></h2>
<p>Actually, you have already been using multithreading in your Python
code, although you might not have realized it.</p>
<p>(We are, as usual, assuming that you are running the latest version of
Anaconda Python.)</p>
<p>This is because NumPy cleverly implements multithreading in a lot of its
compiled code.</p>
<p>Let’s look at some examples to see this in action.</p>
<section id="a-matrix-operation">
<h3>A Matrix Operation<a class="headerlink" href="#a-matrix-operation" title="Permalink to this headline">#</a></h3>
<p>The next piece of code computes the eigenvalues of a large number of
randomly generated matrices.</p>
<p>It takes a few seconds to run.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
    <span class="n">λ</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now, let’s look at the output of the <code class="docutils literal notranslate"><span class="pre">htop</span></code> system monitor
on our machine while this code is running:</p>
<figure class="align-default">
<a class="reference internal image-reference" href="../_images/htop_parallel_npmat.png"><img alt="../_images/htop_parallel_npmat.png" src="../_images/htop_parallel_npmat.png" style="width: 406.90000000000003px; height: 252.85000000000002px;" /></a>
</figure>
<p>We can see that 4 of the 8 CPUs are running at full speed.</p>
<p>This is because NumPy’s <code class="docutils literal notranslate"><span class="pre">eigvals</span></code> routine neatly splits up the tasks
and distributes them to different threads.</p>
</section>
<section id="a-multithreaded-ufunc">
<h3>A Multithreaded Ufunc<a class="headerlink" href="#a-multithreaded-ufunc" title="Permalink to this headline">#</a></h3>
<p>Over the last few years, NumPy has managed to push this kind of
multithreading out to more and more operations.</p>
<p>For example, let’s return to a maximization problem
<a class="reference internal" href="need_for_speed.html#ufuncs"><span class="std std-ref">discussed previously</span></a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5000</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">grid</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">timeit</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>If you have a system monitor such as <code class="docutils literal notranslate"><span class="pre">htop</span></code> (Linux/Mac) or
<code class="docutils literal notranslate"><span class="pre">perfmon</span></code> (Windows), then try running this and then
observing the load on your CPUs.</p>
<p>(You will probably need to bump up the grid size to see large effects.)</p>
<p>At least on our machine, the output shows that the operation is
successfully distributed across multiple threads.</p>
<p>This is one of the reasons why the vectorized code above is fast.</p>
</section>
<section id="a-comparison-with-numba">
<h3>A Comparison with Numba<a class="headerlink" href="#a-comparison-with-numba" title="Permalink to this headline">#</a></h3>
<p>To get some basis for comparison for the last example, let’s try the
same thing with Numba.</p>
<p>In fact there is an easy way to do this, since Numba can also be used to
create custom <a class="reference internal" href="need_for_speed.html#ufuncs"><span class="std std-ref">ufuncs</span></a> with the
<a class="reference external" href="http://numba.pydata.org/numba-doc/dev/user/vectorize.html">&#64;vectorize</a>
decorator.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">vectorize</span>

<span class="nd">@vectorize</span>
<span class="k">def</span> <span class="nf">f_vec</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">f_vec</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>  <span class="c1"># Run once to compile</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">timeit</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">f_vec</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>At least on our machine, the difference in the speed between the Numba
version and the vectorized NumPy version shown above is not large.</p>
<p>But there’s quite a bit going on here so let’s try to break down what
is happening.</p>
<p>Both Numba and NumPy use efficient machine code that’s specialized to
these floating point operations.</p>
<p>However, the code NumPy uses is, in some ways, less efficient.</p>
<p>The reason is that, in NumPy, the operation
<code class="docutils literal notranslate"><span class="pre">np.cos(x**2</span> <span class="pre">+</span> <span class="pre">y**2)</span> <span class="pre">/</span> <span class="pre">(1</span> <span class="pre">+</span> <span class="pre">x**2</span> <span class="pre">+</span> <span class="pre">y**2)</span></code> generates several intermediate
arrays.</p>
<p>For example, a new array is created when <code class="docutils literal notranslate"><span class="pre">x**2</span></code> is calculated.</p>
<p>The same is true when <code class="docutils literal notranslate"><span class="pre">y**2</span></code> is calculated, and then <code class="docutils literal notranslate"><span class="pre">x**2</span> <span class="pre">+</span> <span class="pre">y**2</span></code> and
so on.</p>
<p>Numba avoids creating all these intermediate arrays by compiling one
function that is specialized to the entire operation.</p>
<p>But if this is true, then why isn’t the Numba code faster?</p>
<p>The reason is that NumPy makes up for its disadvantages with implicit
multithreading, as we’ve just discussed.</p>
</section>
<section id="multithreading-a-numba-ufunc">
<h3>Multithreading a Numba Ufunc<a class="headerlink" href="#multithreading-a-numba-ufunc" title="Permalink to this headline">#</a></h3>
<p>Can we get both of these advantages at once?</p>
<p>In other words, can we pair</p>
<ul class="simple">
<li><p>the efficiency of Numba’s highly specialized JIT compiled function
and</p></li>
<li><p>the speed gains from parallelization obtained by NumPy’s implicit
multithreading?</p></li>
</ul>
<p>It turns out that we can, by adding some type information plus
<code class="docutils literal notranslate"><span class="pre">target='parallel'</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@vectorize</span><span class="p">(</span><span class="s1">&#39;float64(float64, float64)&#39;</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;parallel&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">f_vec</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">f_vec</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>  <span class="c1"># Run once to compile</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">timeit</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">f_vec</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Now our code runs significantly faster than the NumPy version.</p>
</section>
</section>
<section id="multithreaded-loops-in-numba">
<h2>Multithreaded Loops in Numba<a class="headerlink" href="#multithreaded-loops-in-numba" title="Permalink to this headline">#</a></h2>
<p>We just saw one approach to parallelization in Numba, using the
<code class="docutils literal notranslate"><span class="pre">parallel</span></code> flag in <code class="docutils literal notranslate"><span class="pre">&#64;vectorize</span></code>.</p>
<p>This is neat but, it turns out, not well suited to many problems we
consider.</p>
<p>Fortunately, Numba provides another approach to multithreading that will
work for us almost everywhere parallelization is possible.</p>
<p>To illustrate, let’s look first at a simple, single-threaded (i.e.,
non-parallelized) piece of code.</p>
<p>The code simulates updating the wealth <span class="math notranslate nohighlight">\(w_t\)</span> of a household via the rule</p>
<div class="math notranslate nohighlight">
\[
w_{t+1} = R_{t+1} s w_t + y_{t+1}
\]</div>
<p>Here</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(R\)</span> is the gross rate of return on assets</p></li>
<li><p><span class="math notranslate nohighlight">\(s\)</span> is the savings rate of the household and</p></li>
<li><p><span class="math notranslate nohighlight">\(y\)</span> is labor income.</p></li>
</ul>
<p>We model both <span class="math notranslate nohighlight">\(R\)</span> and <span class="math notranslate nohighlight">\(y\)</span> as independent draws from a lognormal
distribution.</p>
<p>Here’s the code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">randn</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">njit</span>

<span class="nd">@njit</span>
<span class="k">def</span> <span class="nf">h</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">v2</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Updates household wealth.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Draw shocks</span>
    <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">v1</span> <span class="o">*</span> <span class="n">randn</span><span class="p">())</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">r</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">v2</span> <span class="o">*</span> <span class="n">randn</span><span class="p">())</span>

    <span class="c1"># Update wealth</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">R</span> <span class="o">*</span> <span class="n">s</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="n">y</span>
    <span class="k">return</span> <span class="n">w</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s have a look at how wealth evolves under this rule.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">T</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
<span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">w</span><span class="p">[</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">h</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$t$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$w_</span><span class="si">{t}</span><span class="s1">$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s suppose that we have a large population of households and we
want to know what median wealth will be.</p>
<p>This is not easy to solve with pencil and paper, so we will use
simulation instead.</p>
<p>In particular, we will simulate a large number of households and then
calculate median wealth for this group.</p>
<p>Suppose we are interested in the long-run average of this median over
time.</p>
<p>It turns out that, for the specification that we’ve chosen above, we
can calculate this by taking a one-period snapshot of what has happened
to median wealth of the group at the end of a long simulation.</p>
<p>Moreover, provided the simulation period is long enough, initial
conditions don’t matter.</p>
<ul class="simple">
<li><p>This is due to something called ergodicity, which we will discuss <a class="reference external" href="https://python-intro.quantecon.org/finite_markov.html#Ergodicity">later on</a>.</p></li>
</ul>
<p>So, in summary, we are going to simulate 50,000 households by</p>
<ol class="simple">
<li><p>arbitrarily setting initial wealth to 1 and</p></li>
<li><p>simulating forward in time for 1,000 periods.</p></li>
</ol>
<p>Then we’ll calculate median wealth at the end period.</p>
<p>Here’s the code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@njit</span>
<span class="k">def</span> <span class="nf">compute_long_run_median</span><span class="p">(</span><span class="n">w0</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">num_reps</span><span class="o">=</span><span class="mi">50_000</span><span class="p">):</span>

    <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">num_reps</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_reps</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w0</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">h</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="n">obs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s see how fast this runs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">compute_long_run_median</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>To speed this up, we’re going to parallelize it via multithreading.</p>
<p>To do so, we add the <code class="docutils literal notranslate"><span class="pre">parallel=True</span></code> flag and change <code class="docutils literal notranslate"><span class="pre">range</span></code> to
<code class="docutils literal notranslate"><span class="pre">prange</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">prange</span>

<span class="nd">@njit</span><span class="p">(</span><span class="n">parallel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">compute_long_run_median_parallel</span><span class="p">(</span><span class="n">w0</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">num_reps</span><span class="o">=</span><span class="mi">50_000</span><span class="p">):</span>

    <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">num_reps</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">prange</span><span class="p">(</span><span class="n">num_reps</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w0</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">h</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="n">obs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s look at the timing:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">compute_long_run_median_parallel</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The speed-up is significant.</p>
<section id="a-warning">
<h3>A Warning<a class="headerlink" href="#a-warning" title="Permalink to this headline">#</a></h3>
<p>Parallelization works well in the outer loop of the last example because
the individual tasks inside the loop are independent of each other.</p>
<p>If this independence fails then parallelization is often problematic.</p>
<p>For example, each step inside the inner loop depends on the last step,
so independence fails, and this is why we use ordinary <code class="docutils literal notranslate"><span class="pre">range</span></code> instead
of <code class="docutils literal notranslate"><span class="pre">prange</span></code>.</p>
<p>When you see us using <code class="docutils literal notranslate"><span class="pre">prange</span></code> in later lectures, it is because the
independence of tasks holds true.</p>
<p>When you see us using ordinary <code class="docutils literal notranslate"><span class="pre">range</span></code> in a jitted function, it is
either because the speed gain from parallelization is small or because
independence fails.</p>
</section>
</section>
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">#</a></h2>
<section id="exercise-1">
<h3>Exercise 1<a class="headerlink" href="#exercise-1" title="Permalink to this headline">#</a></h3>
<p>In <a class="reference internal" href="numba.html#speed-ex1"><span class="std std-ref">an earlier exercise</span></a>, we
used Numba to accelerate an effort to compute the constant <span class="math notranslate nohighlight">\(\pi\)</span> by
Monte Carlo.</p>
<p>Now try adding parallelization and see if you get further speed gains.</p>
<p>You should not expect huge gains here because, while there are many
independent tasks (draw point and test if in circle), each one has low
execution time.</p>
<p>Generally speaking, parallelization is less effective when the
individual tasks to be parallelized are very small relative to total
execution time.</p>
<p>This is due to overheads associated with spreading all of these small
tasks across multiple CPUs.</p>
<p>Nevertheless, with suitable hardware, it is possible to get nontrivial
speed gains in this exercise.</p>
<p>For the size of the Monte Carlo simulation, use something substantial,
such as <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">=</span> <span class="pre">100_000_000</span></code>.</p>
</section>
</section>
<section id="solutions">
<h2>Solutions<a class="headerlink" href="#solutions" title="Permalink to this headline">#</a></h2>
<section id="id1">
<h3>Exercise 1<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>Here is one solution:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">uniform</span>

<span class="nd">@njit</span><span class="p">(</span><span class="n">parallel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">calculate_pi</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1_000_000</span><span class="p">):</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">prange</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">u</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">d</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">area_estimate</span> <span class="o">=</span> <span class="n">count</span> <span class="o">/</span> <span class="n">n</span>
    <span class="k">return</span> <span class="n">area_estimate</span> <span class="o">*</span> <span class="mi">4</span>  <span class="c1"># dividing by radius**2</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s see how fast it runs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">time</span> <span class="n">calculate_pi</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">time</span> <span class="n">calculate_pi</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>By switching parallelization on and off (selecting <code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">False</span></code> in
the <code class="docutils literal notranslate"><span class="pre">&#64;njit</span></code> annotation), we can test the speed gain that multithreading
provides on top of JIT compilation.</p>
<p>On our workstation, we find that parallelization increases execution
speed by a factor of 2 or 3.</p>
<p>(If you are executing locally, you will get different numbers, depending
mainly on the number of CPUs on your machine.)</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="numba.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Numba</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="pandas.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Pandas</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Thomas J. Sargent and John Stachurski<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>